# ğŸ¤– ProlinkeetAI â€” Assistant Personnel Telegram avec LLaMA et FastAPI

**ProlinkeetAI** est un assistant personnel numÃ©rique conÃ§u pour offrir une expÃ©rience utilisateur fluide et intelligente via un **bot Telegram**. Ce projet exploite des technologies avancÃ©es telles que le modÃ¨le **LLaMA 4** de Meta, lâ€™API **Groq**, et **FastAPI** pour fournir des rÃ©ponses contextuelles prÃ©cises et des interactions vocales naturelles. Le code est hÃ©bergÃ© sur **Render**, garantissant une disponibilitÃ© continue grÃ¢ce Ã  **UptimeRobot**.

---

## ğŸš€ FonctionnalitÃ©s

- **ğŸ’¬ RÃ©ponses instantanÃ©es** : RÃ©pond aux messages texte envoyÃ©s sur Telegram avec des rÃ©ponses contextuelles et pertinentes.
- **ğŸ™ï¸ Transcription vocale** : Convertit les messages vocaux en texte (en franÃ§ais) grÃ¢ce Ã  Google Speech Recognition.
- **ğŸ§  Intelligence contextuelle** : GÃ©nÃ¨re des rÃ©ponses basÃ©es sur le modÃ¨le **LLaMA 4** via lâ€™API Groq.
- **ğŸ”Š SynthÃ¨se vocale** : Produit des rÃ©ponses vocales synthÃ©tisÃ©es avec `gTTS`, converties en `.mp3` pour une compatibilitÃ© avec Telegram.
- **ğŸŒ Endpoint HTTP** : Fournit une interface HTTP via **FastAPI** pour vÃ©rifier la santÃ© de lâ€™application.
- **â˜ï¸ DÃ©ploiement cloud** : HÃ©bergÃ© sur **Render.com**, avec maintien actif via **UptimeRobot** qui effectue un `HEAD` sur lâ€™API toutes les 5 minutes pour Ã©viter lâ€™endormissement.

---

## ğŸ“‚ Architecture du Projet

### Structure des Dossiers

- **`main.py`** : Point dâ€™entrÃ©e principal du bot Telegram et du serveur FastAPI.
- **`ask_llm.py`** : Gestion des interactions avec le modÃ¨le LLaMA et historique des conversations.
- **`utils.py`** : Fonctions utilitaires pour la transcription vocale et la gestion des fichiers.
- **`settings.py`** : Configuration des variables dâ€™environnement et des paramÃ¨tres systÃ¨me.
- **`build.sh`** : Script dâ€™installation des dÃ©pendances et des outils nÃ©cessaires.
- **`media/`** : RÃ©pertoire pour les fichiers audio (ogg et mp3).
- **`data/`** : Contient les historiques des conversations.

---

## ğŸ› ï¸ Installation et DÃ©ploiement

### PrÃ©requis

- **Python 3.10+**
- **Render.com** pour lâ€™hÃ©bergement
- **UptimeRobot** pour la surveillance

### Ã‰tapes dâ€™Installation

1. Clonez le dÃ©pÃ´t :
   ```bash
   git clone <URL_du_dÃ©pÃ´t>
   cd TelegramChatLLM
   ```

2. Installez les dÃ©pendances :
   ```bash
   bash build.sh
   ```

3. Configurez les variables dâ€™environnement :
   - CrÃ©ez un fichier `.env` Ã  la racine.
   - Ajoutez les clÃ©s nÃ©cessaires :
     ```env
     BOT_TOKEN=<Votre_Token_Telegram>
     GROQ_API_KEY=<Votre_API_Key_Groq>
     ```

4. Lancez lâ€™application localement :
   ```bash
   python main.py
   ```

5. DÃ©ployez sur Render.com en suivant les instructions de leur documentation.

---

## ğŸ“– Fonctionnement

### Interaction avec Telegram

- **Commandes** :
  - `/start` : DÃ©marre une conversation avec le bot.
  - Messages texte : RÃ©ponses instantanÃ©es basÃ©es sur le contexte.
  - Messages vocaux : Transcription et rÃ©ponse vocale.

### Endpoint HTTP

- **`GET /`** : VÃ©rifie la santÃ© de lâ€™application.
- **UptimeRobot** : Effectue un `HEAD` toutes les 5 minutes pour maintenir lâ€™API active.

---

## ğŸ§‘â€ğŸ’» Contributions

Les contributions sont les bienvenues ! Veuillez soumettre vos pull requests ou ouvrir des issues pour signaler des bugs ou proposer des amÃ©liorations.

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.